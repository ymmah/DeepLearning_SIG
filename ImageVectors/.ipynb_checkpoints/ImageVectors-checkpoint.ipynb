{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Begin the clustering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elliott.park/anaconda3/envs/dls/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply the mighty PCA to reduce the dimensions of the data\n",
      "Process reduced data\n",
      "Copy images\n",
      "Fin\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import os\n",
    "from shutil import copyfile\n",
    "# sys.path.append(\"..\")  # Adds higher directory to python modules path.\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Init\n",
    "\n",
    "# Check out the doc to see what this all is http://pytorch.org/docs/master/torchvision/models.html\n",
    "cuda = False\n",
    "model = models.resnet18(pretrained=True)\n",
    "output_layer = model._modules.get('avgpool')\n",
    "image_vector_length = 512\n",
    "        \n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Done with init\n",
    "\n",
    "def get_image_vector(img):\n",
    "\n",
    "    if cuda:\n",
    "        image = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
    "    else:\n",
    "        image = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "\n",
    "    embedding = torch.zeros(image_vector_length)\n",
    "\n",
    "    def copy_data(m, i, o):\n",
    "        embedding.copy_(o.data)\n",
    "\n",
    "    h = output_layer.register_forward_hook(copy_data)\n",
    "    h_x = model(image)\n",
    "    h.remove()\n",
    "\n",
    "    return embedding.numpy()\n",
    "\n",
    "def cluster_images(pca=False):\n",
    "    input_path = './images/unclustered'\n",
    "    files = os.listdir(input_path)\n",
    "    samples = len(files)\n",
    "    num_clusters = 6 # Images were sampled from 6 subreddits. Play around with this number\n",
    "    image_vector_holder = np.zeros((samples, image_vector_length))\n",
    "    sample_indices = np.random.choice(range(0, len(files)), size=samples, replace=False) # randomly sample files\n",
    "\n",
    "    print('Begin the clustering')\n",
    "    for index, i in enumerate(sample_indices):\n",
    "        file = files[i]\n",
    "        if not file.endswith(\".jpg\"):\n",
    "            continue\n",
    "        filename = os.fsdecode(file)\n",
    "        img = Image.open(os.path.join(input_path, filename))\n",
    "        # The model only works with images with 3 channels, i.e. RGB images.\n",
    "        # If the image isn't RGB, convert it\n",
    "        if not img.mode == 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        vec = get_image_vector(img)\n",
    "        image_vector_holder[index, :] = vec\n",
    "\n",
    "    reduced_data = None\n",
    "    if pca:\n",
    "        print('Apply the mighty PCA to reduce the dimensions of the data')\n",
    "        # I'm not sure why this is set to 2 in all the examples I've seen and haven't looked into it yet\n",
    "        reduced_data = PCA(n_components=10).fit_transform(image_vector_holder)\n",
    "    else:\n",
    "        reduced_data = image_vector_holder\n",
    "    \n",
    "    kmeans = KMeans(init='k-means++', n_clusters=num_clusters, n_init=10)\n",
    "    kmeans.fit(reduced_data)\n",
    "\n",
    "    # Create directories for each cluster.\n",
    "    for i in set(kmeans.labels_):\n",
    "        try:\n",
    "            os.mkdir('./images/' + str(i))\n",
    "        except FileExistsError:\n",
    "            continue\n",
    "\n",
    "    print('Process reduced data')\n",
    "    preds = kmeans.predict(reduced_data)\n",
    "\n",
    "    print('Copy images')\n",
    "    for index, i in enumerate(sample_indices):\n",
    "        file = files[i]\n",
    "        filename = os.fsdecode(file)\n",
    "        copyfile(input_path + '/' + filename, './images/' + str(preds[index]) + '/' + filename)\n",
    "\n",
    "    \n",
    "print(\"Starting\")\n",
    "cluster_images(False)\n",
    "print(\"Fin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
